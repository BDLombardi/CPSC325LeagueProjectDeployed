{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import random \n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from riotwatcher import LolWatcher, ApiError, RiotWatcher\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "import random\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(\"data_2.json\",\"r\")\n",
    "dataset = json.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "columns=[\"W_TOP\",\"W_JUNGLE\",\"W_MIDDLE\",\"W_BOTTOM\",\"W_SUPPORT\",\"W_BARON\",\"W_BARON_FIRST\",\"W_DRAGON\",\"W_DRAGON_FIRST\",\"W_CHAMPS\",\"W_CHAMPS_FIRST\",\"W_INHIB\",\"W_INHIB_FIRST\",\"W_RIFT\",\"W_RIFT_FIRST\",\"W_TOWER\",\"W_TOWER_FIRST\",\n",
    "                           \"L_TOP\",\"L_JUNGLE\",\"L_MIDDLE\",\"L_BOTTOM\",\"L_SUPPORT\",\"L_BARON\",\"L_BARON_FIRST\",\"L_DRAGON\",\"L_DRAGON_FIRST\",\"L_CHAMPS\",\"L_CHAMPS_FIRST\",\"L_INHIB\",\"L_INHIB_FIRST\",\"L_RIFT\",\"L_RIFT_FIRST\",\"L_TOWER\",\"L_TOWER_FIRST\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "w_top =[]\n",
    "w_jg = []\n",
    "w_mid = []\n",
    "w_bot = []\n",
    "w_sup = []\n",
    "\n",
    "l_top = []\n",
    "l_jg = []\n",
    "l_mid = []\n",
    "l_bot = []\n",
    "l_sup = []\n",
    "\n",
    "w_drag = []\n",
    "w_drag_first = []\n",
    "w_baron = []\n",
    "w_baron_first = []\n",
    "w_champs = []\n",
    "w_champs_first = []\n",
    "w_inhib = []\n",
    "w_inhib_first = []\n",
    "w_rift = []\n",
    "w_rift_first = []\n",
    "w_tower = []\n",
    "w_tower_first = []\n",
    "\n",
    "l_drag = []\n",
    "l_drag_first = []\n",
    "l_baron = []\n",
    "l_baron_first = []\n",
    "l_champs = []\n",
    "l_champs_first = []\n",
    "l_inhib = []\n",
    "l_inhib_first = []\n",
    "l_rift = []\n",
    "l_rift_first = []\n",
    "l_tower = []\n",
    "l_tower_first = []\n",
    "\n",
    "i = 0\n",
    "for match in dataset:\n",
    "    temp_players = []\n",
    "    if match[\"info\"][\"gameMode\"] == \"CLASSIC\" and match[\"info\"][\"gameType\"] == \"MATCHED_GAME\" and len(match[\"metadata\"][\"participants\"]) == 10 and len(match[\"info\"][\"participants\"]) == 10:\n",
    "        teams = match[\"info\"][\"teams\"]\n",
    "        for team in teams:\n",
    "            if team[\"win\"] == True:\n",
    "                w_baron_first.append(int(team[\"objectives\"][\"baron\"][\"first\"]))\n",
    "                w_baron.append(int(team[\"objectives\"][\"baron\"][\"kills\"]))\n",
    "                w_drag_first.append(int(team[\"objectives\"][\"dragon\"][\"first\"]))\n",
    "                w_drag.append(int(team[\"objectives\"][\"dragon\"][\"kills\"]))\n",
    "                w_champs_first.append(int(team[\"objectives\"][\"champion\"][\"first\"]))\n",
    "                w_champs.append(int(team[\"objectives\"][\"champion\"][\"kills\"]))\n",
    "                w_inhib_first.append(int(team[\"objectives\"][\"inhibitor\"][\"first\"]))\n",
    "                w_inhib.append(int(team[\"objectives\"][\"inhibitor\"][\"kills\"]))\n",
    "                w_rift_first.append(int(team[\"objectives\"][\"riftHerald\"][\"first\"]))\n",
    "                w_rift.append(int(team[\"objectives\"][\"riftHerald\"][\"kills\"]))\n",
    "                w_tower_first.append(int(team[\"objectives\"][\"tower\"][\"first\"]))\n",
    "                w_tower.append(int(team[\"objectives\"][\"tower\"][\"kills\"]))\n",
    "\n",
    "            if team[\"win\"] == False:\n",
    "                l_baron_first.append(int(team[\"objectives\"][\"baron\"][\"first\"]))\n",
    "                l_baron.append(int(team[\"objectives\"][\"baron\"][\"kills\"]))\n",
    "                l_drag_first.append(int(team[\"objectives\"][\"dragon\"][\"first\"]))\n",
    "                l_drag.append(int(team[\"objectives\"][\"dragon\"][\"kills\"]))\n",
    "                l_champs_first.append(int(team[\"objectives\"][\"champion\"][\"first\"]))\n",
    "                l_champs.append(int(team[\"objectives\"][\"champion\"][\"kills\"]))\n",
    "                l_inhib_first.append(int(team[\"objectives\"][\"inhibitor\"][\"first\"]))\n",
    "                l_inhib.append(int(team[\"objectives\"][\"inhibitor\"][\"kills\"]))\n",
    "                l_rift_first.append(int(team[\"objectives\"][\"riftHerald\"][\"first\"]))\n",
    "                l_rift.append(int(team[\"objectives\"][\"riftHerald\"][\"kills\"]))\n",
    "                l_tower_first.append(int(team[\"objectives\"][\"tower\"][\"first\"]))\n",
    "                l_tower.append(int(team[\"objectives\"][\"tower\"][\"kills\"]))\n",
    "\n",
    "        for player in match[\"info\"][\"participants\"]:\n",
    "            if player[\"win\"] == True and player[\"teamPosition\"] == \"TOP\":\n",
    "                w_top.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == True and player[\"teamPosition\"] == \"JUNGLE\":\n",
    "                w_jg.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == True and player[\"teamPosition\"] == \"MIDDLE\":\n",
    "                w_mid.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == True and player[\"teamPosition\"] == \"BOTTOM\":\n",
    "                w_bot.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == True and player[\"teamPosition\"] == \"UTILITY\":\n",
    "                w_sup.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == False and player[\"teamPosition\"] == \"TOP\":\n",
    "                l_top.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == False and player[\"teamPosition\"] == \"JUNGLE\":\n",
    "                l_jg.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == False and player[\"teamPosition\"] == \"MIDDLE\":\n",
    "                l_mid.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == False and player[\"teamPosition\"] == \"BOTTOM\":\n",
    "                l_bot.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == False and player[\"teamPosition\"] == \"UTILITY\":\n",
    "                l_sup.append(player[\"championId\"])\n",
    "            else:\n",
    "                temp_players.append(player[\"championId\"])\n",
    "        if len(temp_players) != 0:\n",
    "            for t_player in temp_players:\n",
    "                player_pos = [w_top, w_jg, w_mid, w_bot, w_sup, l_top, l_jg, l_mid, l_bot, l_sup]\n",
    "                for position in player_pos:\n",
    "                    if len(position) == i:\n",
    "                        position.append(t_player)\n",
    "        i+=1\n",
    "pos = [w_top, w_jg, w_mid, w_bot, w_sup, w_baron, w_baron_first, w_drag, w_drag_first, w_champs, w_champs_first, w_inhib, w_inhib_first, w_rift, w_rift_first, \n",
    "       w_tower, w_tower_first, l_top, l_jg, l_mid, l_bot, l_sup, l_baron, l_baron_first, l_drag, l_drag_first, l_champs, l_champs_first, l_inhib, l_inhib_first,\n",
    "        l_rift, l_rift_first, l_tower, l_tower_first]\n",
    "for i in range(len(pos)):\n",
    "    # print(len(pos[i]))\n",
    "    df.insert(loc=i,column=columns[i],value=pos[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       W_BARON_FIRST  W_DRAGON_FIRST  W_CHAMPS_FIRST  W_INHIB_FIRST  \\\n",
      "0                  0               0               0              0   \n",
      "1                  0               1               0              0   \n",
      "2                  1               0               1              1   \n",
      "3                  1               0               0              1   \n",
      "4                  1               0               1              0   \n",
      "...              ...             ...             ...            ...   \n",
      "45585              0               0               1              0   \n",
      "45586              0               1               1              1   \n",
      "45587              0               1               0              0   \n",
      "45588              1               1               0              1   \n",
      "45589              1               1               1              1   \n",
      "\n",
      "       W_RIFT_FIRST  W_TOWER_FIRST  \n",
      "0                 0              0  \n",
      "1                 1              0  \n",
      "2                 1              1  \n",
      "3                 1              1  \n",
      "4                 1              1  \n",
      "...             ...            ...  \n",
      "45585             0              0  \n",
      "45586             1              1  \n",
      "45587             1              1  \n",
      "45588             0              0  \n",
      "45589             1              1  \n",
      "\n",
      "[45590 rows x 6 columns]\n",
      "       L_BARON_FIRST  L_DRAGON_FIRST  L_CHAMPS_FIRST  L_INHIB_FIRST  \\\n",
      "0                  1               1               1              1   \n",
      "1                  0               0               1              0   \n",
      "2                  0               1               0              0   \n",
      "3                  0               1               1              0   \n",
      "4                  0               1               0              1   \n",
      "...              ...             ...             ...            ...   \n",
      "45585              0               1               0              0   \n",
      "45586              1               0               0              0   \n",
      "45587              0               0               1              0   \n",
      "45588              0               0               1              0   \n",
      "45589              0               0               0              0   \n",
      "\n",
      "       L_RIFT_FIRST  L_TOWER_FIRST  \n",
      "0                 1              1  \n",
      "1                 0              1  \n",
      "2                 0              0  \n",
      "3                 0              0  \n",
      "4                 0              0  \n",
      "...             ...            ...  \n",
      "45585             0              0  \n",
      "45586             0              0  \n",
      "45587             0              0  \n",
      "45588             1              1  \n",
      "45589             0              0  \n",
      "\n",
      "[45590 rows x 6 columns]\n",
      "0.6041675806097828\n",
      "0.12540030708488703\n"
     ]
    }
   ],
   "source": [
    "#print(df.iloc[:,0:7])\n",
    "#print(df.iloc[:,17:25])\n",
    "print(df.iloc[:,[6,8,10,12,14,16]])\n",
    "print(df.iloc[:,[23,25,27,29,31,33]])\n",
    "print(df.iloc[:,6].to_list().count(1)/len(df))\n",
    "print(df.iloc[:,23].to_list().count(1)/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45590\n"
     ]
    }
   ],
   "source": [
    "win_team = []\n",
    "lose_team = []\n",
    "# for i in range(len(df)):\n",
    "#     win_team.append(list(df.iloc[i][0:5]))\n",
    "\n",
    "# print(win_team)\n",
    "win_team = df.iloc[:,0:5].values.tolist()\n",
    "obj_w = df.iloc[:,[6,8,10,14,16]].values.tolist()\n",
    "lose_team = df.iloc[:,17:22].values.tolist()\n",
    "obj_l = df.iloc[:,[23,25,27,31,33]].values.tolist()\n",
    "y = []\n",
    "x = []\n",
    "for i in range(len(win_team)):\n",
    "    swap =  random.randint(0,1)\n",
    "    y.append(swap)\n",
    "    if swap == 0:\n",
    "        x.append(obj_w[i] + obj_l[i])\n",
    "        #x.append(win_team[i] + [obj_w[i]] + lose_team[i] + [obj_l[i]])\n",
    "        #x.append(win_team[i] + lose_team[i])\n",
    "    else:\n",
    "        x.append(obj_l[i] + obj_w[i])\n",
    "        #x.append(lose_team[i] + [obj_l[i]] + win_team[i] + [obj_w[i]])\n",
    "        #x.append(lose_team[i] + win_team[i])\n",
    "\n",
    "print(len(x))\n",
    "X_train,X_val,y_train,y_val = train_test_split(x,y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(\"data3.json\",\"r\")\n",
    "dataset = json.load(infile)\n",
    "infile.close()\n",
    "columns=[\"W_TOP\",\"W_JUNGLE\",\"W_MIDDLE\",\"W_BOTTOM\",\"W_SUPPORT\",\"W_BARON\",\"W_BARON_FIRST\",\"W_DRAGON\",\"W_DRAGON_FIRST\",\"W_CHAMPS\",\"W_CHAMPS_FIRST\",\"W_INHIB\",\"W_INHIB_FIRST\",\"W_RIFT\",\"W_RIFT_FIRST\",\"W_TOWER\",\"W_TOWER_FIRST\",\n",
    "                           \"L_TOP\",\"L_JUNGLE\",\"L_MIDDLE\",\"L_BOTTOM\",\"L_SUPPORT\",\"L_BARON\",\"L_BARON_FIRST\",\"L_DRAGON\",\"L_DRAGON_FIRST\",\"L_CHAMPS\",\"L_CHAMPS_FIRST\",\"L_INHIB\",\"L_INHIB_FIRST\",\"L_RIFT\",\"L_RIFT_FIRST\",\"L_TOWER\",\"L_TOWER_FIRST\"]\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "w_top =[]\n",
    "w_jg = []\n",
    "w_mid = []\n",
    "w_bot = []\n",
    "w_sup = []\n",
    "\n",
    "l_top = []\n",
    "l_jg = []\n",
    "l_mid = []\n",
    "l_bot = []\n",
    "l_sup = []\n",
    "\n",
    "w_drag = []\n",
    "w_drag_first = []\n",
    "w_baron = []\n",
    "w_baron_first = []\n",
    "w_champs = []\n",
    "w_champs_first = []\n",
    "w_inhib = []\n",
    "w_inhib_first = []\n",
    "w_rift = []\n",
    "w_rift_first = []\n",
    "w_tower = []\n",
    "w_tower_first = []\n",
    "\n",
    "l_drag = []\n",
    "l_drag_first = []\n",
    "l_baron = []\n",
    "l_baron_first = []\n",
    "l_champs = []\n",
    "l_champs_first = []\n",
    "l_inhib = []\n",
    "l_inhib_first = []\n",
    "l_rift = []\n",
    "l_rift_first = []\n",
    "l_tower = []\n",
    "l_tower_first = []\n",
    "\n",
    "i = 0\n",
    "for match in dataset:\n",
    "    temp_players = []\n",
    "    if match[\"info\"][\"gameMode\"] == \"CLASSIC\" and match[\"info\"][\"gameType\"] == \"MATCHED_GAME\" and len(match[\"metadata\"][\"participants\"]) == 10 and len(match[\"info\"][\"participants\"]) == 10:\n",
    "        teams = match[\"info\"][\"teams\"]\n",
    "        for team in teams:\n",
    "            if team[\"win\"] == True:\n",
    "                w_baron_first.append(int(team[\"objectives\"][\"baron\"][\"first\"]))\n",
    "                w_baron.append(int(team[\"objectives\"][\"baron\"][\"kills\"]))\n",
    "                w_drag_first.append(int(team[\"objectives\"][\"dragon\"][\"first\"]))\n",
    "                w_drag.append(int(team[\"objectives\"][\"dragon\"][\"kills\"]))\n",
    "                w_champs_first.append(int(team[\"objectives\"][\"champion\"][\"first\"]))\n",
    "                w_champs.append(int(team[\"objectives\"][\"champion\"][\"kills\"]))\n",
    "                w_inhib_first.append(int(team[\"objectives\"][\"inhibitor\"][\"first\"]))\n",
    "                w_inhib.append(int(team[\"objectives\"][\"inhibitor\"][\"kills\"]))\n",
    "                w_rift_first.append(int(team[\"objectives\"][\"riftHerald\"][\"first\"]))\n",
    "                w_rift.append(int(team[\"objectives\"][\"riftHerald\"][\"kills\"]))\n",
    "                w_tower_first.append(int(team[\"objectives\"][\"tower\"][\"first\"]))\n",
    "                w_tower.append(int(team[\"objectives\"][\"tower\"][\"kills\"]))\n",
    "\n",
    "            if team[\"win\"] == False:\n",
    "                l_baron_first.append(int(team[\"objectives\"][\"baron\"][\"first\"]))\n",
    "                l_baron.append(int(team[\"objectives\"][\"baron\"][\"kills\"]))\n",
    "                l_drag_first.append(int(team[\"objectives\"][\"dragon\"][\"first\"]))\n",
    "                l_drag.append(int(team[\"objectives\"][\"dragon\"][\"kills\"]))\n",
    "                l_champs_first.append(int(team[\"objectives\"][\"champion\"][\"first\"]))\n",
    "                l_champs.append(int(team[\"objectives\"][\"champion\"][\"kills\"]))\n",
    "                l_inhib_first.append(int(team[\"objectives\"][\"inhibitor\"][\"first\"]))\n",
    "                l_inhib.append(int(team[\"objectives\"][\"inhibitor\"][\"kills\"]))\n",
    "                l_rift_first.append(int(team[\"objectives\"][\"riftHerald\"][\"first\"]))\n",
    "                l_rift.append(int(team[\"objectives\"][\"riftHerald\"][\"kills\"]))\n",
    "                l_tower_first.append(int(team[\"objectives\"][\"tower\"][\"first\"]))\n",
    "                l_tower.append(int(team[\"objectives\"][\"tower\"][\"kills\"]))\n",
    "\n",
    "        for player in match[\"info\"][\"participants\"]:\n",
    "            if player[\"win\"] == True and player[\"teamPosition\"] == \"TOP\":\n",
    "                w_top.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == True and player[\"teamPosition\"] == \"JUNGLE\":\n",
    "                w_jg.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == True and player[\"teamPosition\"] == \"MIDDLE\":\n",
    "                w_mid.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == True and player[\"teamPosition\"] == \"BOTTOM\":\n",
    "                w_bot.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == True and player[\"teamPosition\"] == \"UTILITY\":\n",
    "                w_sup.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == False and player[\"teamPosition\"] == \"TOP\":\n",
    "                l_top.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == False and player[\"teamPosition\"] == \"JUNGLE\":\n",
    "                l_jg.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == False and player[\"teamPosition\"] == \"MIDDLE\":\n",
    "                l_mid.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == False and player[\"teamPosition\"] == \"BOTTOM\":\n",
    "                l_bot.append(player[\"championId\"])\n",
    "            elif player[\"win\"] == False and player[\"teamPosition\"] == \"UTILITY\":\n",
    "                l_sup.append(player[\"championId\"])\n",
    "            else:\n",
    "                temp_players.append(player[\"championId\"])\n",
    "        if len(temp_players) != 0:\n",
    "            for t_player in temp_players:\n",
    "                player_pos = [w_top, w_jg, w_mid, w_bot, w_sup, l_top, l_jg, l_mid, l_bot, l_sup]\n",
    "                for position in player_pos:\n",
    "                    if len(position) == i:\n",
    "                        position.append(t_player)\n",
    "        i+=1\n",
    "pos = [w_top, w_jg, w_mid, w_bot, w_sup, w_baron, w_baron_first, w_drag, w_drag_first, w_champs, w_champs_first, w_inhib, w_inhib_first, w_rift, w_rift_first, \n",
    "       w_tower, w_tower_first, l_top, l_jg, l_mid, l_bot, l_sup, l_baron, l_baron_first, l_drag, l_drag_first, l_champs, l_champs_first, l_inhib, l_inhib_first,\n",
    "        l_rift, l_rift_first, l_tower, l_tower_first]\n",
    "for i in range(len(pos)):\n",
    "    # print(len(pos[i]))\n",
    "    df_test.insert(loc=i,column=columns[i],value=pos[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_team = []\n",
    "lose_team = []\n",
    "# for i in range(len(df)):\n",
    "#     win_team.append(list(df.iloc[i][0:5]))\n",
    "\n",
    "# print(win_team)\n",
    "win_team = df_test.iloc[:,0:5].values.tolist()\n",
    "#obj_w = df_test.iloc[:,[6,8,10,14,16]].values.tolist()\n",
    "obj_w = df_test.iloc[:,6].values.tolist()\n",
    "lose_team = df_test.iloc[:,17:22].values.tolist()\n",
    "#obj_l = df_test.iloc[:,[23,25,27,31,33]].values.tolist()\n",
    "obj_l = df_test.iloc[:,23].values.tolist()\n",
    "y_test = []\n",
    "X_test = []\n",
    "for i in range(len(win_team)):\n",
    "    swap =  random.randint(0,1)\n",
    "    y_test.append(swap)\n",
    "    if swap == 0:\n",
    "        #X_test.append(obj_w[i] + obj_l[i])\n",
    "        X_test.append(win_team[i] + [obj_w[i]] + lose_team[i] + [obj_l[i]])\n",
    "        #X_test.append(win_team[i] + lose_team[i])\n",
    "    else:\n",
    "        #X_test.append(obj_l[i] + obj_w[i])\n",
    "        X_test.append(lose_team[i] + [obj_l[i]] + win_team[i] + [obj_w[i]])\n",
    "        #X_test.append(lose_team[i] + win_team[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8138528138528138\n",
      "[[558 128]\n",
      " [130 570]]\n",
      "0.8102453102453102\n",
      "[[551 135]\n",
      " [128 572]]\n",
      "0.8138528138528138\n",
      "[[558 128]\n",
      " [130 570]]\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test,y_pred)\n",
    "print(accuracy)\n",
    "print(sklearn.metrics.confusion_matrix(y_test,y_pred))\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=10)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_pred = knn_clf.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test,y_pred)\n",
    "print(accuracy)\n",
    "print(sklearn.metrics.confusion_matrix(y_test,y_pred))\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=35)\n",
    "forest_clf.fit(X_train,y_train)\n",
    "y_pred = forest_clf.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test,y_pred)\n",
    "print(accuracy)\n",
    "print(sklearn.metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "776/776 [==============================] - 4s 5ms/step - loss: 0.5467 - accuracy: 0.6994 - val_loss: 0.4190 - val_accuracy: 0.8349 - lr: 0.0010\n",
      "Epoch 2/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4199 - accuracy: 0.8352 - val_loss: 0.4135 - val_accuracy: 0.8301 - lr: 0.0010\n",
      "Epoch 3/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4181 - accuracy: 0.8344 - val_loss: 0.4132 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 4/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4181 - accuracy: 0.8347 - val_loss: 0.4122 - val_accuracy: 0.8340 - lr: 0.0010\n",
      "Epoch 5/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4176 - accuracy: 0.8350 - val_loss: 0.4204 - val_accuracy: 0.8302 - lr: 0.0010\n",
      "Epoch 6/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4180 - accuracy: 0.8343 - val_loss: 0.4221 - val_accuracy: 0.8320 - lr: 0.0010\n",
      "Epoch 7/400\n",
      "776/776 [==============================] - 6s 7ms/step - loss: 0.4175 - accuracy: 0.8336 - val_loss: 0.4109 - val_accuracy: 0.8340 - lr: 0.0010\n",
      "Epoch 8/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4169 - accuracy: 0.8346 - val_loss: 0.4105 - val_accuracy: 0.8370 - lr: 0.0010\n",
      "Epoch 9/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4171 - accuracy: 0.8347 - val_loss: 0.4162 - val_accuracy: 0.8314 - lr: 0.0010\n",
      "Epoch 10/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4169 - accuracy: 0.8342 - val_loss: 0.4098 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 11/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4166 - accuracy: 0.8345 - val_loss: 0.4122 - val_accuracy: 0.8370 - lr: 0.0010\n",
      "Epoch 12/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4160 - accuracy: 0.8343 - val_loss: 0.4204 - val_accuracy: 0.8302 - lr: 0.0010\n",
      "Epoch 13/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4158 - accuracy: 0.8355 - val_loss: 0.4108 - val_accuracy: 0.8340 - lr: 0.0010\n",
      "Epoch 14/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4154 - accuracy: 0.8360 - val_loss: 0.4084 - val_accuracy: 0.8409 - lr: 0.0010\n",
      "Epoch 15/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4149 - accuracy: 0.8344 - val_loss: 0.4078 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 16/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4144 - accuracy: 0.8357 - val_loss: 0.4081 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 17/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4137 - accuracy: 0.8345 - val_loss: 0.4067 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 18/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4122 - accuracy: 0.8347 - val_loss: 0.4052 - val_accuracy: 0.8340 - lr: 0.0010\n",
      "Epoch 19/400\n",
      "776/776 [==============================] - 4s 5ms/step - loss: 0.4105 - accuracy: 0.8372 - val_loss: 0.4069 - val_accuracy: 0.8351 - lr: 0.0010\n",
      "Epoch 20/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4102 - accuracy: 0.8353 - val_loss: 0.4028 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 21/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4085 - accuracy: 0.8362 - val_loss: 0.4016 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 22/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4086 - accuracy: 0.8368 - val_loss: 0.4039 - val_accuracy: 0.8327 - lr: 0.0010\n",
      "Epoch 23/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4077 - accuracy: 0.8363 - val_loss: 0.4004 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 24/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4063 - accuracy: 0.8368 - val_loss: 0.3989 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 25/400\n",
      "776/776 [==============================] - 5s 6ms/step - loss: 0.4056 - accuracy: 0.8367 - val_loss: 0.3981 - val_accuracy: 0.8396 - lr: 0.0010\n",
      "Epoch 26/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4057 - accuracy: 0.8363 - val_loss: 0.4047 - val_accuracy: 0.8396 - lr: 0.0010\n",
      "Epoch 27/400\n",
      "776/776 [==============================] - 4s 5ms/step - loss: 0.4050 - accuracy: 0.8365 - val_loss: 0.3989 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 28/400\n",
      "776/776 [==============================] - 4s 5ms/step - loss: 0.4045 - accuracy: 0.8373 - val_loss: 0.4005 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 29/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4045 - accuracy: 0.8368 - val_loss: 0.3960 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 30/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4043 - accuracy: 0.8375 - val_loss: 0.3962 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 31/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4042 - accuracy: 0.8369 - val_loss: 0.3978 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 32/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4048 - accuracy: 0.8375 - val_loss: 0.3995 - val_accuracy: 0.8396 - lr: 0.0010\n",
      "Epoch 33/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4040 - accuracy: 0.8371 - val_loss: 0.4013 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 34/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4041 - accuracy: 0.8376 - val_loss: 0.3967 - val_accuracy: 0.8396 - lr: 0.0010\n",
      "Epoch 35/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4040 - accuracy: 0.8366 - val_loss: 0.3970 - val_accuracy: 0.8409 - lr: 0.0010\n",
      "Epoch 36/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4035 - accuracy: 0.8377 - val_loss: 0.3963 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 37/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4039 - accuracy: 0.8373 - val_loss: 0.3969 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 38/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4037 - accuracy: 0.8378 - val_loss: 0.3959 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 39/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4037 - accuracy: 0.8368 - val_loss: 0.3961 - val_accuracy: 0.8409 - lr: 0.0010\n",
      "Epoch 40/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4036 - accuracy: 0.8378 - val_loss: 0.3960 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 41/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4035 - accuracy: 0.8377 - val_loss: 0.3966 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 42/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4034 - accuracy: 0.8376 - val_loss: 0.4002 - val_accuracy: 0.8396 - lr: 0.0010\n",
      "Epoch 43/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4038 - accuracy: 0.8370 - val_loss: 0.3968 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 44/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4035 - accuracy: 0.8371 - val_loss: 0.3964 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 45/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4031 - accuracy: 0.8374 - val_loss: 0.3969 - val_accuracy: 0.8396 - lr: 0.0010\n",
      "Epoch 46/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4035 - accuracy: 0.8367 - val_loss: 0.3972 - val_accuracy: 0.8409 - lr: 0.0010\n",
      "Epoch 47/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4036 - accuracy: 0.8368 - val_loss: 0.3965 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 48/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4032 - accuracy: 0.8377 - val_loss: 0.3978 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 49/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4034 - accuracy: 0.8372 - val_loss: 0.3981 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 50/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4031 - accuracy: 0.8372 - val_loss: 0.3968 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 51/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4032 - accuracy: 0.8375 - val_loss: 0.3991 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 52/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4033 - accuracy: 0.8377 - val_loss: 0.3957 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 53/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4030 - accuracy: 0.8381 - val_loss: 0.3962 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 54/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4032 - accuracy: 0.8373 - val_loss: 0.3980 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 55/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4032 - accuracy: 0.8370 - val_loss: 0.3978 - val_accuracy: 0.8409 - lr: 0.0010\n",
      "Epoch 56/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4036 - accuracy: 0.8375 - val_loss: 0.3971 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 57/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4030 - accuracy: 0.8371 - val_loss: 0.3959 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 58/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4030 - accuracy: 0.8373 - val_loss: 0.3964 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 59/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4028 - accuracy: 0.8377 - val_loss: 0.3963 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 60/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4031 - accuracy: 0.8372 - val_loss: 0.4002 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 61/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4033 - accuracy: 0.8378 - val_loss: 0.3963 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 62/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4029 - accuracy: 0.8376 - val_loss: 0.3959 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 63/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4029 - accuracy: 0.8376 - val_loss: 0.3974 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 64/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4029 - accuracy: 0.8372 - val_loss: 0.3956 - val_accuracy: 0.8409 - lr: 0.0010\n",
      "Epoch 65/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4029 - accuracy: 0.8372 - val_loss: 0.3970 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 66/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4029 - accuracy: 0.8378 - val_loss: 0.3957 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 67/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4029 - accuracy: 0.8375 - val_loss: 0.3959 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 68/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4027 - accuracy: 0.8378 - val_loss: 0.3965 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 69/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4023 - accuracy: 0.8376 - val_loss: 0.3993 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 70/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4028 - accuracy: 0.8371 - val_loss: 0.3965 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 71/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4027 - accuracy: 0.8378 - val_loss: 0.3969 - val_accuracy: 0.8409 - lr: 0.0010\n",
      "Epoch 72/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4033 - accuracy: 0.8374 - val_loss: 0.3960 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 73/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4028 - accuracy: 0.8379 - val_loss: 0.3958 - val_accuracy: 0.8409 - lr: 0.0010\n",
      "Epoch 74/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4027 - accuracy: 0.8378 - val_loss: 0.3959 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 75/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4026 - accuracy: 0.8382 - val_loss: 0.3960 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 76/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4026 - accuracy: 0.8379 - val_loss: 0.3990 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 77/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4026 - accuracy: 0.8372 - val_loss: 0.3976 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 78/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4029 - accuracy: 0.8375 - val_loss: 0.3969 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 79/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4031 - accuracy: 0.8374 - val_loss: 0.3959 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 80/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4028 - accuracy: 0.8373 - val_loss: 0.3963 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 81/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4027 - accuracy: 0.8373 - val_loss: 0.3988 - val_accuracy: 0.8409 - lr: 0.0010\n",
      "Epoch 82/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4027 - accuracy: 0.8377 - val_loss: 0.3986 - val_accuracy: 0.8406 - lr: 0.0010\n",
      "Epoch 83/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4029 - accuracy: 0.8379 - val_loss: 0.3959 - val_accuracy: 0.8409 - lr: 0.0010\n",
      "Epoch 84/400\n",
      "764/776 [============================>.] - ETA: 0s - loss: 0.4026 - accuracy: 0.8374\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4025 - accuracy: 0.8374 - val_loss: 0.3959 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 85/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4015 - accuracy: 0.8377 - val_loss: 0.3971 - val_accuracy: 0.8397 - lr: 5.0000e-04\n",
      "Epoch 86/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4020 - accuracy: 0.8369 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 87/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4019 - accuracy: 0.8378 - val_loss: 0.3958 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 88/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4016 - accuracy: 0.8378 - val_loss: 0.3960 - val_accuracy: 0.8409 - lr: 5.0000e-04\n",
      "Epoch 89/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4018 - accuracy: 0.8376 - val_loss: 0.3955 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 90/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4016 - accuracy: 0.8375 - val_loss: 0.3959 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 91/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4017 - accuracy: 0.8377 - val_loss: 0.3962 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 92/400\n",
      "776/776 [==============================] - 2s 3ms/step - loss: 0.4016 - accuracy: 0.8381 - val_loss: 0.3968 - val_accuracy: 0.8397 - lr: 5.0000e-04\n",
      "Epoch 93/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4021 - accuracy: 0.8377 - val_loss: 0.3959 - val_accuracy: 0.8409 - lr: 5.0000e-04\n",
      "Epoch 94/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4016 - accuracy: 0.8376 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 95/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4017 - accuracy: 0.8381 - val_loss: 0.3961 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 96/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4018 - accuracy: 0.8380 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 97/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4016 - accuracy: 0.8376 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 98/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4017 - accuracy: 0.8379 - val_loss: 0.3965 - val_accuracy: 0.8397 - lr: 5.0000e-04\n",
      "Epoch 99/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4019 - accuracy: 0.8380 - val_loss: 0.3955 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 100/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4016 - accuracy: 0.8378 - val_loss: 0.3955 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 101/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4018 - accuracy: 0.8379 - val_loss: 0.3959 - val_accuracy: 0.8409 - lr: 5.0000e-04\n",
      "Epoch 102/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4016 - accuracy: 0.8380 - val_loss: 0.3960 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 103/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4019 - accuracy: 0.8380 - val_loss: 0.3955 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 104/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4021 - accuracy: 0.8380 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 105/400\n",
      "776/776 [==============================] - 2s 3ms/step - loss: 0.4017 - accuracy: 0.8381 - val_loss: 0.3959 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 106/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4017 - accuracy: 0.8376 - val_loss: 0.3958 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 107/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4017 - accuracy: 0.8373 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 108/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4016 - accuracy: 0.8377 - val_loss: 0.3957 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 109/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4019 - accuracy: 0.8377 - val_loss: 0.3958 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 110/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4017 - accuracy: 0.8377 - val_loss: 0.3978 - val_accuracy: 0.8409 - lr: 5.0000e-04\n",
      "Epoch 111/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4018 - accuracy: 0.8377 - val_loss: 0.3955 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 112/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4018 - accuracy: 0.8378 - val_loss: 0.3957 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 113/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4019 - accuracy: 0.8378 - val_loss: 0.3961 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 114/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4018 - accuracy: 0.8376 - val_loss: 0.3961 - val_accuracy: 0.8397 - lr: 5.0000e-04\n",
      "Epoch 115/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4016 - accuracy: 0.8380 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 116/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4016 - accuracy: 0.8379 - val_loss: 0.3959 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 117/400\n",
      "772/776 [============================>.] - ETA: 0s - loss: 0.4018 - accuracy: 0.8382\n",
      "Epoch 117: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "776/776 [==============================] - 2s 3ms/step - loss: 0.4017 - accuracy: 0.8381 - val_loss: 0.3958 - val_accuracy: 0.8415 - lr: 5.0000e-04\n",
      "Epoch 118/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8381 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 119/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8378 - val_loss: 0.3955 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 120/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8379 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 121/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4013 - accuracy: 0.8380 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 122/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4012 - accuracy: 0.8380 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 123/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4014 - accuracy: 0.8377 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 124/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4012 - accuracy: 0.8378 - val_loss: 0.3955 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 125/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8380 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 126/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8380 - val_loss: 0.3957 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 127/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4012 - accuracy: 0.8380 - val_loss: 0.3957 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 128/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8378 - val_loss: 0.3956 - val_accuracy: 0.8397 - lr: 2.5000e-04\n",
      "Epoch 129/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4013 - accuracy: 0.8374 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 130/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4012 - accuracy: 0.8378 - val_loss: 0.3957 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 131/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4014 - accuracy: 0.8377 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 132/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8381 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 133/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8381 - val_loss: 0.3952 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 134/400\n",
      "776/776 [==============================] - 4s 5ms/step - loss: 0.4012 - accuracy: 0.8382 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 135/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4012 - accuracy: 0.8379 - val_loss: 0.3957 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 136/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8379 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 137/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4012 - accuracy: 0.8381 - val_loss: 0.3956 - val_accuracy: 0.8397 - lr: 2.5000e-04\n",
      "Epoch 138/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4014 - accuracy: 0.8379 - val_loss: 0.3957 - val_accuracy: 0.8397 - lr: 2.5000e-04\n",
      "Epoch 139/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4011 - accuracy: 0.8378 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 140/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4012 - accuracy: 0.8379 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 141/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8379 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 142/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8381 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 143/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8377 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 144/400\n",
      "776/776 [==============================] - 4s 5ms/step - loss: 0.4011 - accuracy: 0.8377 - val_loss: 0.3959 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 145/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8381 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 146/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8379 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 147/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4012 - accuracy: 0.8378 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 148/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4012 - accuracy: 0.8380 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 149/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4012 - accuracy: 0.8378 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 150/400\n",
      "776/776 [==============================] - 4s 5ms/step - loss: 0.4013 - accuracy: 0.8379 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 151/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8377 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 152/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4012 - accuracy: 0.8377 - val_loss: 0.3958 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 153/400\n",
      "770/776 [============================>.] - ETA: 0s - loss: 0.4014 - accuracy: 0.8376\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4012 - accuracy: 0.8377 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 2.5000e-04\n",
      "Epoch 154/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4010 - accuracy: 0.8378 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 155/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4010 - accuracy: 0.8379 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 156/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4010 - accuracy: 0.8380 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 157/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.4010 - accuracy: 0.8380 - val_loss: 0.3958 - val_accuracy: 0.8409 - lr: 1.2500e-04\n",
      "Epoch 158/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4011 - accuracy: 0.8378 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 159/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4010 - accuracy: 0.8380 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 160/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4010 - accuracy: 0.8381 - val_loss: 0.3955 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 161/400\n",
      "776/776 [==============================] - 2s 3ms/step - loss: 0.4010 - accuracy: 0.8378 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 162/400\n",
      "776/776 [==============================] - 2s 3ms/step - loss: 0.4009 - accuracy: 0.8380 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 163/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4010 - accuracy: 0.8380 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 164/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4011 - accuracy: 0.8379 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 165/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4011 - accuracy: 0.8380 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 166/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4010 - accuracy: 0.8380 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 167/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4010 - accuracy: 0.8380 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 168/400\n",
      "776/776 [==============================] - 2s 3ms/step - loss: 0.4010 - accuracy: 0.8380 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 169/400\n",
      "776/776 [==============================] - 2s 3ms/step - loss: 0.4010 - accuracy: 0.8379 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 170/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4010 - accuracy: 0.8379 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 171/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4011 - accuracy: 0.8379 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 172/400\n",
      "776/776 [==============================] - 2s 3ms/step - loss: 0.4009 - accuracy: 0.8380 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 173/400\n",
      "774/776 [============================>.] - ETA: 0s - loss: 0.4011 - accuracy: 0.8379\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4010 - accuracy: 0.8379 - val_loss: 0.3956 - val_accuracy: 0.8415 - lr: 1.2500e-04\n",
      "Epoch 174/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4009 - accuracy: 0.8380 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 6.2500e-05\n",
      "Epoch 175/400\n",
      "776/776 [==============================] - 2s 3ms/step - loss: 0.4010 - accuracy: 0.8380 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 6.2500e-05\n",
      "Epoch 176/400\n",
      "776/776 [==============================] - 2s 3ms/step - loss: 0.4009 - accuracy: 0.8380 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 6.2500e-05\n",
      "Epoch 177/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4009 - accuracy: 0.8380 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 6.2500e-05\n",
      "Epoch 178/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4009 - accuracy: 0.8380 - val_loss: 0.3954 - val_accuracy: 0.8415 - lr: 6.2500e-05\n",
      "Epoch 179/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4009 - accuracy: 0.8380 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 6.2500e-05\n",
      "Epoch 180/400\n",
      "776/776 [==============================] - 2s 3ms/step - loss: 0.4009 - accuracy: 0.8380 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 6.2500e-05\n",
      "Epoch 181/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4009 - accuracy: 0.8380 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 6.2500e-05\n",
      "Epoch 182/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.4009 - accuracy: 0.8380 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 6.2500e-05\n",
      "Epoch 183/400\n",
      "765/776 [============================>.] - ETA: 0s - loss: 0.4005 - accuracy: 0.8382Restoring model weights from the end of the best epoch: 133.\n",
      "776/776 [==============================] - 2s 3ms/step - loss: 0.4009 - accuracy: 0.8380 - val_loss: 0.3953 - val_accuracy: 0.8415 - lr: 6.2500e-05\n",
      "Epoch 183: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Reshape(target_shape=(10,),input_shape=(10,)),\n",
    "        tf.keras.layers.Dense(units = 30,activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(units = 30,activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(units=30,activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(units = 30,activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(units = 30,activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(units = 30,activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(units = 30,activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(units=2,activation='softmax')\n",
    "    ])\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join('ckpt', \"{epoch:02d}-{val_loss:.4f}.hdf5\"),\n",
    "        monitor = 'val_loss',\n",
    "        verbose = 0,\n",
    "        save_best_only = True,\n",
    "        save_weights_only = False,\n",
    "        mode = 'auto',\n",
    "        save_freq='epoch',\n",
    "        options=None,\n",
    "        initial_value_threshold=None,\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        mode='auto',\n",
    "        min_delta=0.0001,\n",
    "        cooldown=0,\n",
    "        min_lr=0,\n",
    "        ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0,\n",
    "        patience=50,\n",
    "        verbose=1,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "history = model.fit(X_train,y_train,batch_size=50,callbacks = callbacks, epochs=400,validation_data=(X_val,y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 2ms/step\n",
      "[[556 130]\n",
      " [130 570]]\n",
      "0.8124098124098124\n",
      "(array([0.81049563, 0.81428571]), array([0.81049563, 0.81428571]), array([0.81049563, 0.81428571]), array([686, 700], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "\n",
    "mat = sklearn.metrics.confusion_matrix(y_test,y_pred)\n",
    "print(mat)\n",
    "print((mat[0][0]+mat[1][1])/len(y_pred))\n",
    "print(sklearn.metrics.precision_recall_fscore_support(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 3ms/step\n",
      "[[647  68]\n",
      " [363 308]]\n",
      "0.689033189033189\n",
      "(array([0.64059406, 0.81914894]), array([0.9048951 , 0.45901639]), array([0.75014493, 0.58834766]), array([715, 671], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "obj_mod = tf.keras.models.load_model('pred_models/comp_bf/143-0.5252.hdf5')\n",
    "y_pred = obj_mod.predict(X_test)\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "\n",
    "mat = sklearn.metrics.confusion_matrix(y_test,y_pred)\n",
    "print(mat)\n",
    "print((mat[0][0]+mat[1][1])/len(y_pred))\n",
    "print(sklearn.metrics.precision_recall_fscore_support(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5577200577200577\n",
      "0.5897345909190612\n"
     ]
    }
   ],
   "source": [
    "#Rift Herald Frequency\n",
    "print(df_test.iloc[:,14].values.tolist().count(1)/len(df_test))\n",
    "print(df.iloc[:,14].values.tolist().count(1)/len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47186147186147187\n",
      "0.6041675806097828\n"
     ]
    }
   ],
   "source": [
    "#Baron Frequency\n",
    "print(df_test.iloc[:,6].values.tolist().count(1)/len(df_test))\n",
    "print(df.iloc[:,6].values.tolist().count(1)/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6132756132756133\n",
      "0.6408642246106603\n"
     ]
    }
   ],
   "source": [
    "# Dragon Frequency\n",
    "print(df_test.iloc[:,8].values.tolist().count(1)/len(df_test))\n",
    "print(df.iloc[:,8].values.tolist().count(1)/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8585858585858586\n",
      "[[622  81]\n",
      " [115 568]]\n",
      "(array([0.84396201, 0.8751926 ]), array([0.88477952, 0.83162518]), array([0.86388889, 0.85285285]), array([703, 683], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "y_pred = forest_clf.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test,y_pred)\n",
    "print(accuracy)\n",
    "print(sklearn.metrics.confusion_matrix(y_test,y_pred))\n",
    "print(sklearn.metrics.precision_recall_fscore_support(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "#joblib.dump(forest_clf,'pred_models/comp_rf/forest_clf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8138528138528138\n",
      "[[558 128]\n",
      " [130 570]]\n",
      "(array([0.81104651, 0.81661891]), array([0.81341108, 0.81428571]), array([0.81222707, 0.81545064]), array([686, 700], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#clf = joblib.load('pred_models/comp_rf/forest_clf.pkl')\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test,y_pred)\n",
    "print(accuracy)\n",
    "print(sklearn.metrics.confusion_matrix(y_test,y_pred))\n",
    "print(sklearn.metrics.precision_recall_fscore_support(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_20 (Reshape)        (None, 10, 1)             0         \n",
      "                                                                 \n",
      " conv1d_50 (Conv1D)          (None, 9, 5)              15        \n",
      "                                                                 \n",
      " conv1d_51 (Conv1D)          (None, 8, 5)              55        \n",
      "                                                                 \n",
      " conv1d_52 (Conv1D)          (None, 7, 5)              55        \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 35)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 20)                720       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,497\n",
      "Trainable params: 1,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "776/776 [==============================] - 4s 5ms/step - loss: 0.6951 - accuracy: 0.4963 - val_loss: 0.6937 - val_accuracy: 0.4859 - lr: 0.0010\n",
      "Epoch 2/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6941 - accuracy: 0.4963 - val_loss: 0.6939 - val_accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 3/400\n",
      "776/776 [==============================] - 4s 5ms/step - loss: 0.6938 - accuracy: 0.4976 - val_loss: 0.6937 - val_accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 4/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6935 - accuracy: 0.5024 - val_loss: 0.6927 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 5/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6934 - accuracy: 0.5014 - val_loss: 0.6928 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 6/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6933 - accuracy: 0.5051 - val_loss: 0.6929 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 7/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 8/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.5018 - val_loss: 0.6928 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 9/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4943 - val_loss: 0.6932 - val_accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 10/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4946 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 11/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6929 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 12/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6929 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 13/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 14/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 15/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 16/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6932 - val_accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 17/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 18/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6932 - val_accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 19/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 20/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 21/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6932 - val_accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 22/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6929 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 23/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6932 - val_accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 24/400\n",
      "769/776 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5014\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6928 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 25/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6932 - val_accuracy: 0.4862 - lr: 5.0000e-04\n",
      "Epoch 26/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 5.0000e-04\n",
      "Epoch 27/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 5.0000e-04\n",
      "Epoch 28/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.4862 - lr: 5.0000e-04\n",
      "Epoch 29/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6932 - val_accuracy: 0.4862 - lr: 5.0000e-04\n",
      "Epoch 30/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.4862 - lr: 5.0000e-04\n",
      "Epoch 31/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 5.0000e-04\n",
      "Epoch 32/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6932 - val_accuracy: 0.4862 - lr: 5.0000e-04\n",
      "Epoch 33/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 5.0000e-04\n",
      "Epoch 34/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 5.0000e-04\n",
      "Epoch 35/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4959 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 5.0000e-04\n",
      "Epoch 36/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 5.0000e-04\n",
      "Epoch 37/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6932 - val_accuracy: 0.4862 - lr: 5.0000e-04\n",
      "Epoch 38/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 5.0000e-04\n",
      "Epoch 39/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 5.0000e-04\n",
      "Epoch 40/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 5.0000e-04\n",
      "Epoch 41/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.5007 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 5.0000e-04\n",
      "Epoch 42/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 5.0000e-04\n",
      "Epoch 43/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 5.0000e-04\n",
      "Epoch 44/400\n",
      "758/776 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.4998\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 5.0000e-04\n",
      "Epoch 45/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 2.5000e-04\n",
      "Epoch 46/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 2.5000e-04\n",
      "Epoch 47/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 2.5000e-04\n",
      "Epoch 48/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 2.5000e-04\n",
      "Epoch 49/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 2.5000e-04\n",
      "Epoch 50/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 2.5000e-04\n",
      "Epoch 51/400\n",
      "776/776 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6930 - val_accuracy: 0.5138 - lr: 2.5000e-04\n",
      "Epoch 52/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 2.5000e-04\n",
      "Epoch 53/400\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 2.5000e-04\n",
      "Epoch 54/400\n",
      "773/776 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.4992Restoring model weights from the end of the best epoch: 4.\n",
      "776/776 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5138 - lr: 2.5000e-04\n",
      "Epoch 54: early stopping\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Reshape(target_shape=(10,1),input_shape=(10,1)),\n",
    "        tf.keras.layers.Conv1D(5,2,activation='sigmoid',input_shape=(10,1)),\n",
    "        tf.keras.layers.Conv1D(5,2,activation='sigmoid',input_shape=(9,1)),\n",
    "        tf.keras.layers.Conv1D(5,2,activation='sigmoid',input_shape=(8,1)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units=20,activation='relu'),\n",
    "        tf.keras.layers.Dense(units=20,activation='relu'),\n",
    "        tf.keras.layers.Dense(units=10,activation='relu'),\n",
    "        tf.keras.layers.Dense(units=2,activation='softmax')\n",
    "    ])\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join('ckpt', \"{epoch:02d}-{val_loss:.4f}.hdf5\"),\n",
    "        monitor = 'val_loss',\n",
    "        verbose = 0,\n",
    "        save_best_only = True,\n",
    "        save_weights_only = False,\n",
    "        mode = 'auto',\n",
    "        save_freq='epoch',\n",
    "        options=None,\n",
    "        initial_value_threshold=None,\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        mode='auto',\n",
    "        min_delta=0.0001,\n",
    "        cooldown=0,\n",
    "        min_lr=0,\n",
    "        ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0,\n",
    "        patience=50,\n",
    "        verbose=1,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "model2.compile(optimizer=\"adam\",loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "history = model2.fit(X_train,y_train,batch_size=50,callbacks = callbacks, epochs=400,validation_data=(X_val,y_val))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
